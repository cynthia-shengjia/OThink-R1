```markdown
# OThink-R1 è¯„æµ‹æŒ‡å— (BENCHMARK_README.md)

> æœ¬æ–‡æ¡£è¯´æ˜å¦‚ä½•ä½¿ç”¨ `othink_cli.py` åœ¨ A100 é›†ç¾¤ä¸Šè¿›è¡Œä¸€é”®éƒ¨ç½²å’Œè¯„æµ‹ã€‚

---

## 1. å¿«é€Ÿå¼€å§‹ (4 æ­¥è·‘é€š)

```bash
# â‘  æ¿€æ´»ç¯å¢ƒ
conda activate othink-r1

# â‘¡ ä¸‹è½½æ•°æ®é›† + æ¨¡å‹
python othink_cli.py download-data  --datasets math aime asdiv
python othink_cli.py download-model --model Qwen/Qwen2.5-0.5B-Instruct

# â‘¢ è¿è¡Œ DEER è¯„æµ‹ (å•å¡)
python othink_cli.py eval-deer --model Qwen2.5-0.5B-Instruct --datasets math --gpu_ids 0

# â‘£ ä¸€é”®å…¨é‡è¯„æµ‹ (8å¡å¹¶è¡Œ)
python othink_cli.py eval-all --model Qwen2.5-0.5B-Instruct --gpu_ids 0,1,2,3,4,5,6,7
```

---

## 2. ç¯å¢ƒå‡†å¤‡

### 2.1 åˆ›å»ºç¯å¢ƒ
```bash
conda env create -n othink-r1 python=3.11
conda activate othink-r1
```

### 2.2 å®‰è£…ä¾èµ– (uv)
```bash
pip install uv
uv sync
```

### 2.3 éªŒè¯
```bash
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}, GPUs: {torch.cuda.device_count()}')"
python -c "import vllm; print('vLLM OK')"
```

---

## 3. æ•°æ®é›†ä¸‹è½½

### 3.1 ä¸‹è½½å…¨éƒ¨
```bash
python othink_cli.py download-data --datasets all
```

### 3.2 ä¸‹è½½æŒ‡å®šæ•°æ®é›†
```bash
python othink_cli.py download-data --datasets math aime asdiv livecodebench
```

### 3.3 ä½¿ç”¨è‡ªå®šä¹‰é•œåƒ
```bash
python othink_cli.py download-data --datasets all --hf_mirror https://hf-mirror.com
```

### 3.4 æ•°æ®é›†é€ŸæŸ¥è¡¨

| CLI åç§° | HuggingFace ä»“åº“ | æœ¬åœ°è·¯å¾„ | æ”¯æŒè¯„æµ‹ |
|:---------:|:----------------:|:--------:|:--------:|
| `math` | `DigitalLearningGmbH/MATH-lighteval` | `datasets/MATH` | Standard, DEER, CP-Router |
| `aime` | `AI-MO/aimo-validation-aime` | `datasets/AIME` | Standard, DEER, CP-Router |
| `asdiv` | `EleutherAI/asdiv` | `datasets/ASDIV` | Standard, DEER, CP-Router |
| `gsm8k` | `openai/gsm8k` | `datasets/GSM8K` | DEER |
| `gpqa` | `Idavidrein/gpqa` | `datasets/GPQA` | DEER |
| `livecodebench` | `livecodebench/code_generation_lite` | `datasets/livecodebench/...` | LCB |

> ğŸ’¡ ä¸‹è½½å®Œæˆåä¼šè‡ªåŠ¨è°ƒç”¨ `baseline/deer/scripts/convert_hf_to_deer.py` è½¬æ¢ DEER æ ¼å¼ã€‚

---

## 4. æ¨¡å‹ä¸‹è½½

### 4.1 ä» HuggingFace ä¸‹è½½
```bash
python othink_cli.py download-model --model Qwen/Qwen2.5-0.5B-Instruct
python othink_cli.py download-model --model Qwen/Qwen2.5-7B-Instruct
python othink_cli.py download-model --model deepseek-ai/DeepSeek-R1-Distill-Qwen-7B
```

### 4.2 è‡ªå®šä¹‰ä¿å­˜åç§°
```bash
python othink_cli.py download-model --model Qwen/Qwen2.5-7B-Instruct --name Qwen7B
```

### 4.3 é“¾æ¥æœ¬åœ°å·²æœ‰æ¨¡å‹
```bash
python othink_cli.py download-model --model Qwen2.5-7B-Instruct --local_path /data/shared/models/Qwen2.5-7B-Instruct
```

### 4.4 å¹‚ç­‰æ€§
æ‰€æœ‰ä¸‹è½½æ“ä½œéƒ½æ˜¯å¹‚ç­‰çš„ï¼šå¦‚æœ `models/<name>` å·²å­˜åœ¨ä¸”éç©ºï¼Œä¼šè‡ªåŠ¨è·³è¿‡ã€‚

---

## 5. è¯„æµ‹æ–¹å¼è¯¦è§£

### 5.1 æ ‡å‡†è¯„æµ‹ (Standard)

è°ƒç”¨ `OThinkR1Training/eval.py` + Hydra é…ç½®ã€‚

```bash
# å•æ•°æ®é›†
python othink_cli.py eval \
    --model Qwen2.5-0.5B-Instruct \
    --datasets aime \
    --gpu_ids 1

# å¤šæ•°æ®é›†å¹¶è¡Œ (æ¯ä¸ªæ•°æ®é›†åˆ†é…ä¸€å¼ å¡)
python othink_cli.py eval \
    --model Qwen2.5-0.5B-Instruct \
    --datasets math aime asdiv \
    --gpu_ids 0,1,2

# è‡ªå®šä¹‰å‚æ•°
python othink_cli.py eval \
    --model Qwen2.5-0.5B-Instruct \
    --datasets math \
    --gpu_ids 0 \
    --temperature 0.6 \
    --top_p 0.9 \
    --max_tokens 8192
```

### 5.2 DEER è¯„æµ‹ (Dynamic Early Exit)

è°ƒç”¨ `baseline/deer/vllm-deer.py`ï¼Œæ”¯æŒåŠ¨æ€æå‰é€€å‡ºã€‚

```bash
# åŸºæœ¬ç”¨æ³•
python othink_cli.py eval-deer \
    --model Qwen2.5-0.5B-Instruct \
    --datasets aime \
    --gpu_ids 1

# è‡ªå®šä¹‰é˜ˆå€¼å’Œé•¿åº¦
python othink_cli.py eval-deer \
    --model Qwen2.5-0.5B-Instruct \
    --datasets math \
    --gpu_ids 0 \
    --threshold 0.90 \
    --max_len 8192

# æ‰«æå¤šä¸ªé˜ˆå€¼
for t in 0.80 0.85 0.90 0.95 0.99; do
    python othink_cli.py eval-deer \
        --model Qwen2.5-0.5B-Instruct \
        --datasets math \
        --gpu_ids 0 \
        --threshold $t
done
```

**DEER å‚æ•°è¯´æ˜:**

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|:----:|:------:|:----:|
| `--threshold` | 0.95 | é€€å‡ºç½®ä¿¡åº¦é˜ˆå€¼ |
| `--max_len` | 16384 | æœ€å¤§ç”Ÿæˆé•¿åº¦ |

### 5.3 CP-Router è¯„æµ‹

è°ƒç”¨ `baseline/cp-router/test_cp_router.py`ã€‚

```bash
# ä»…è·¯ç”±å†³ç­– (skip LRM)
python othink_cli.py eval-cp-router \
    --llm_model Qwen2.5-0.5B-Instruct \
    --datasets math aime asdiv \
    --gpu_ids 0 \
    --skip_lrm

# ç«¯åˆ°ç«¯ (å« LRM æ¨ç†)
python othink_cli.py eval-cp-router \
    --llm_model Qwen2.5-0.5B-Instruct \
    --lrm_model Qwen2.5-0.5B-Instruct \
    --datasets aime \
    --gpu_ids 1

# è‡ªå®šä¹‰å‚æ•°
python othink_cli.py eval-cp-router \
    --llm_model Qwen2.5-14B-Instruct \
    --lrm_model DeepSeek-R1-Distill-Qwen-14B \
    --datasets math \
    --gpu_ids 0 \
    --tau 1 --beta 3.0 --batch_size 8
```

### 5.4 LiveCodeBench è¯„æµ‹

```bash
# æ ‡å‡†æ¨¡å¼
python othink_cli.py eval-lcb \
    --model Qwen2.5-0.5B-Instruct \
    --mode standard \
    --gpu_ids 0

# DEER æ¨¡å¼
python othink_cli.py eval-lcb \
    --model Qwen2.5-0.5B-Instruct \
    --mode deer \
    --gpu_ids 0 \
    --threshold 0.95

# é™åˆ¶é¢˜ç›®æ•° (å¿«é€Ÿæµ‹è¯•)
python othink_cli.py eval-lcb \
    --model Qwen2.5-0.5B-Instruct \
    --mode standard \
    --gpu_ids 0 \
    --max_problems 5
```

---

## 6. å¤š GPU å¹¶è¡Œè¯„æµ‹

### æ ¸å¿ƒæœºåˆ¶

`othink_cli.py` å†…ç½® `GPUScheduler`ï¼Œç»´æŠ¤ç©ºé—² GPU æ± ï¼š

1. ç”¨æˆ·æŒ‡å®š `--gpu_ids 0,1,2,3`
2. è„šæœ¬å°† (method, dataset) ç»„åˆç”Ÿæˆä»»åŠ¡é˜Ÿåˆ—
3. æœ‰ç©ºé—² GPU æ—¶è‡ªåŠ¨å–ä»»åŠ¡ï¼Œè®¾ç½® `CUDA_VISIBLE_DEVICES` å¯åŠ¨å­è¿›ç¨‹
4. æ‰€æœ‰ä»»åŠ¡å®Œæˆåæ±‡æ€»ç»“æœ

### ç¤ºä¾‹: 4 å¡å¹¶è¡Œ DEER

```bash
# 3 ä¸ªæ•°æ®é›†åˆ†é…åˆ° 4 å¼ å¡ä¸Šå¹¶è¡Œ
python othink_cli.py eval-deer \
    --model Qwen2.5-0.5B-Instruct \
    --datasets math aime asdiv \
    --gpu_ids 0,1,2,3
```

è¾“å‡º:
```
ğŸ“‹ å…± 3 ä¸ªä»»åŠ¡, å¯ç”¨ GPU: [0, 1, 2, 3]
ğŸ–¥ï¸  [START] deer-math  â†’  GPU [0]
ğŸ–¥ï¸  [START] deer-aime  â†’  GPU [1]
ğŸ–¥ï¸  [START] deer-asdiv â†’  GPU [2]
â±ï¸  [DONE] âœ… deer-asdiv  è€—æ—¶ 120.3s  rc=0
â±ï¸  [DONE] âœ… deer-aime   è€—æ—¶ 245.1s  rc=0
â±ï¸  [DONE] âœ… deer-math   è€—æ—¶ 890.2s  rc=0

========================================================================
ğŸ‰ è¯„æµ‹ç»“æœæ±‡æ€»
------------------------------------------------------------------------
  ä»»åŠ¡å                                   GPU        è€—æ—¶     çŠ¶æ€
------------------------------------------------------------------------
  deer-aime                                1          245.1s   âœ…
  deer-asdiv                               2          120.3s   âœ…
  deer-math                                0          890.2s   âœ…
========================================================================
ğŸ‰ æ‰€æœ‰ä»»åŠ¡å‡å·²æˆåŠŸå®Œæˆ!
```

---

## 7. ä¸€é”®å…¨é‡è¯„æµ‹

### 7.1 å…¨æ–¹æ³• + å…¨æ•°æ®é›†

```bash
python othink_cli.py eval-all \
    --model Qwen2.5-0.5B-Instruct \
    --gpu_ids 0,1,2,3,4,5,6,7 \
    --methods standard,deer,cp-router,lcb-standard,lcb-deer \
    --datasets math aime asdiv
```

### 7.2 ä»… Standard + DEER

```bash
python othink_cli.py eval-all \
    --model Qwen2.5-0.5B-Instruct \
    --gpu_ids 0,1,2,3 \
    --methods standard,deer \
    --datasets math aime asdiv
```

### 7.3 å« CP-Router (éœ€æŒ‡å®š LRM)

```bash
python othink_cli.py eval-all \
    --model Qwen2.5-14B-Instruct \
    --lrm_model DeepSeek-R1-Distill-Qwen-14B \
    --gpu_ids 0,1,2,3,4,5,6,7 \
    --methods standard,deer,cp-router \
    --datasets math aime asdiv
```

### 7.4 æ”¯æŒçš„æ–¹æ³•åˆ—è¡¨

| æ–¹æ³•å | è¯´æ˜ | è°ƒç”¨è„šæœ¬ |
|:------:|:----:|:--------:|
| `standard` | æ ‡å‡†è¯„æµ‹ | `OThinkR1Training/eval.py` |
| `deer` | DEER æ—©é€€ | `baseline/deer/vllm-deer.py` |
| `cp-router` | CP-Router è·¯ç”± | `baseline/cp-router/test_cp_router.py` |
| `lcb-standard` | LCB æ ‡å‡† | `benchmark/livecodebench/lcb_eval.py` |
| `lcb-deer` | LCB DEER | `benchmark/livecodebench/deer_lcb.py` |

---

## 8. å®Œæ•´å·¥ä½œæµç¤ºä¾‹

### A100 8å¡é›†ç¾¤å®Œæ•´è¯„æµ‹æµç¨‹

```bash
# 1. ç¯å¢ƒ
conda activate othink-r1

# 2. ä¸‹è½½æ‰€æœ‰æ•°æ®
python othink_cli.py download-data --datasets all

# 3. ä¸‹è½½æ¨¡å‹
python othink_cli.py download-model --model Qwen/Qwen2.5-0.5B-Instruct
python othink_cli.py download-model --model Qwen/Qwen2.5-7B-Instruct
python othink_cli.py download-model --model deepseek-ai/DeepSeek-R1-Distill-Qwen-7B

# 4. å…¨é‡è¯„æµ‹ (8å¡å¹¶è¡Œ)
python othink_cli.py eval-all \
    --model Qwen2.5-7B-Instruct \
    --gpu_ids 0,1,2,3,4,5,6,7 \
    --methods standard,deer \
    --datasets math aime asdiv

# 5. LiveCodeBench å•ç‹¬è·‘ (éœ€è¦ç‹¬å  GPU)
python othink_cli.py eval-lcb \
    --model Qwen2.5-7B-Instruct \
    --mode standard \
    --gpu_ids 0

python othink_cli.py eval-lcb \
    --model Qwen2.5-7B-Instruct \
    --mode deer \
    --gpu_ids 1
```

---

## 9. å¸¸è§é—®é¢˜ (FAQ)

### Q1: ä¸‹è½½æŠ¥ ConnectionError
ç¡®è®¤é•œåƒè®¾ç½®: `--hf_mirror https://hf-mirror.com`

### Q2: CUDA out of memory
- å‡å° `--max_tokens` æˆ– `--max_len`
- ä½¿ç”¨æ›´å°çš„æ¨¡å‹å…ˆæµ‹è¯•
- 14B æ¨¡å‹å»ºè®® 2 å¡ tensor parallel

### Q3: DEER æ•°æ®ä¸å­˜åœ¨
å…ˆè¿è¡Œ `python othink_cli.py download-data --datasets <name>`ï¼Œä¼šè‡ªåŠ¨è½¬æ¢ DEER æ ¼å¼ã€‚

### Q4: å¦‚ä½•åªè·‘å‰ N æ¡æ•°æ®
æ ‡å‡†è¯„æµ‹: åœ¨ Hydra é…ç½®ä¸­è®¾ç½® slice
DEER: ä¿®æ”¹ `baseline/deer/data/<name>/test.jsonl` æˆªå–å‰ N è¡Œ
LCB: ä½¿ç”¨ `--max_problems N`

### Q5: ç»“æœä¿å­˜åœ¨å“ªé‡Œ
- æ ‡å‡†è¯„æµ‹: `OThinkR1Training/save_configs/` å’Œ `OThinkR1Training/log/`
- DEER: `baseline/deer/outputs/<model_name>/<dataset>/`
- CP-Router: `baseline/cp-router/results/`
- LCB: `results/lcb/<model_name>/`

### Q6: å¦‚ä½•æ·»åŠ æ–°æ•°æ®é›†
1. åœ¨ `othink_config.yaml` çš„ `datasets` ä¸‹æ·»åŠ æ¡ç›®
2. åœ¨ `othink_cli.py` çš„ `DATASET_REGISTRY` ä¸­æ·»åŠ å¯¹åº”æ˜ å°„
3. å¦‚éœ€ DEER æ”¯æŒï¼Œåœ¨ `convert_hf_to_deer.py` ä¸­æ·»åŠ è½¬æ¢é€»è¾‘

### Q7: å¦‚ä½•æ·»åŠ æ–°æ¨¡å‹
```bash
# æ–¹æ³•1: ä» HuggingFace ä¸‹è½½
python othink_cli.py download-model --model your-org/your-model

# æ–¹æ³•2: é“¾æ¥æœ¬åœ°æ¨¡å‹
python othink_cli.py download-model --model YourModel --local_path /path/to/model
```
å¦‚éœ€æ ‡å‡†è¯„æµ‹æ”¯æŒï¼Œè¿˜éœ€åœ¨ `OThinkR1Training/config/model/` ä¸‹åˆ›å»º Hydra é…ç½®ã€‚
```